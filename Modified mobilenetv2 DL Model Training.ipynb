{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final MobileNetV2 Model Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Function to print with Markdown\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "\n",
    "\n",
    "# Load and preprocess dataset\n",
    "image_dir = Path(r'E:\\Abroad period research\\new idea implementation codes\\First part of the Covid paper\\Original dataset performance\\Original dataset')\n",
    "\n",
    "filepaths = list(image_dir.glob(r'**/*.png'))\n",
    "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "image_df = pd.concat([filepaths, labels], axis=1)\n",
    "image_df = image_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "train_df, temp_df = train_test_split(image_df, train_size=0.7, shuffle=True, random_state=1)\n",
    "val_df, test_df = train_test_split(temp_df, train_size=0.5, shuffle=True, random_state=1)\n",
    "\n",
    "# Create data generators with augmentation\n",
    "def create_gen():\n",
    "    train_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    val_test_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "    )\n",
    "\n",
    "    train_images = train_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        seed=0\n",
    "    )\n",
    "\n",
    "    val_images = val_test_generator.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    test_images = val_test_generator.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_images, val_images, test_images\n",
    "\n",
    "# Load pre-trained MobileNetV2 model\n",
    "pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "# Unfreeze some layers for fine-tuning\n",
    "pretrained_model.trainable = True\n",
    "for layer in pretrained_model.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create data generators\n",
    "train_images, val_images, test_images = create_gen()\n",
    "\n",
    "# Custom Model with additional layers\n",
    "inputs = pretrained_model.input\n",
    "x = pretrained_model.output\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(len(image_df['Label'].unique()), activation='softmax')(x)\n",
    "\n",
    "# Compile the model using Adam optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Cyclical Learning Rate Callback\n",
    "class CyclicLR(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, base_lr=1e-4, max_lr=1e-2, step_size=2000., mode='triangular'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.clr_iterations = 0\n",
    "        self.history = {}\n",
    "\n",
    "    def clr(self):\n",
    "        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))\n",
    "        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)\n",
    "        lr = self.base_lr + (self.max_lr - self.base_lr) * max(0, (1 - x))\n",
    "        return lr\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.clr_iterations = 0\n",
    "\n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.clr_iterations += 1\n",
    "        logs['lr'] = self.clr()\n",
    "        self.history.setdefault('lr', []).append(logs['lr'])\n",
    "\n",
    "# Callbacks\n",
    "clr = CyclicLR(base_lr=1e-4, max_lr=1e-3, step_size=2000.)\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6),\n",
    "    clr\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('Mobilenetv2_on_Original_Dataset.h5')\n",
    "\n",
    "# Plot accuracy and loss curves\n",
    "pd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot()\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame(history.history)[['loss', 'val_loss']].plot()\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Cyclical Learning Rate\n",
    "plt.plot(clr.history['lr'])\n",
    "plt.title('Cyclical Learning Rate Schedule')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "results = model.evaluate(test_images, verbose=0)\n",
    "printmd(f\"## Test Loss: {results[0]:.5f}\")\n",
    "printmd(f\"## Accuracy on the test set: {results[1] * 100:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute AUC-ROC for each class\n",
    "y_true = test_images.classes  # Actual labels\n",
    "y_pred_proba = model.predict(test_images, verbose=0)  # Predicted probabilities for each class\n",
    "n_classes = len(image_df['Label'].unique())\n",
    "\n",
    "# Binarize the output labels for each class (one-vs-rest)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y_true_binarized = label_binarize(y_true, classes=np.arange(n_classes))\n",
    "\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotting ROC Curve for each class\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"Class {i} (area = {roc_auc[i]:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for each class\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Make predictions\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)  # Assuming train_images is a data generator\n",
    "labels = dict((v, k) for k, v in labels.items())  # Reverse the dictionary to get label mapping\n",
    "pred = [labels[k] for k in pred]\n",
    "\n",
    "# Assuming your test_df contains true labels for comparison\n",
    "y_test = list(test_df['Label'])  # Replace 'Label' with the actual column name containing true labels\n",
    "\n",
    "# Evaluation Metrics\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, pred)\n",
    "\n",
    "# Create the confusion matrix plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', xticklabels=sorted(set(y_test)), yticklabels=sorted(set(y_test)), cmap=\"Blues\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Test-Time Augmentation (TTA), a technique where multiple augmentations of the test images are made, and the modelâ€™s predictions are averaged across those augmentations to improve robustness and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Test-Time Augmentation (TTA)\n",
    "def predict_with_tta(model, test_images, augmentations=5):\n",
    "    tta_predictions = []\n",
    "    \n",
    "    for _ in range(augmentations):\n",
    "        # Generate augmented data by resetting the iterator\n",
    "        test_images.reset()\n",
    "        \n",
    "        # Get predictions for all test images\n",
    "        preds = model.predict(test_images, verbose=0)\n",
    "        tta_predictions.append(preds)\n",
    "    \n",
    "    # Average the predictions across augmentations\n",
    "    return np.mean(tta_predictions, axis=0)\n",
    "\n",
    "# Test-Time Augmentation (TTA) prediction\n",
    "tta_preds = predict_with_tta(model, test_images, augmentations=5)\n",
    "tta_class_preds = np.argmax(tta_preds, axis=1)\n",
    "tta_accuracy = np.mean(tta_class_preds == test_images.classes)  # test_images.classes gives the true labels\n",
    "\n",
    "# Print the TTA accuracy\n",
    "print(f\"TTA Accuracy on the test set: {tta_accuracy * 100:.2f}%\")\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Additional Visualizations for the Paper\n",
    "# ----------------------------------------------\n",
    "\n",
    "# 1. Confusion Matrix with TTA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cf_matrix = confusion_matrix(test_images.classes, tta_class_preds)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap=\"Blues\", \n",
    "            xticklabels=test_images.class_indices, \n",
    "            yticklabels=test_images.class_indices)\n",
    "plt.title('Confusion Matrix - Test-Time Augmentation (TTA)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# 2. ROC and AUC Curves for Each Class\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "num_classes = len(test_images.class_indices)\n",
    "y_true = label_binarize(test_images.classes, classes=[i for i in range(num_classes)])\n",
    "y_score = tta_preds\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves for all classes\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(num_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Test-Time Augmentation (TTA)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# 3. Accuracy Comparison Table\n",
    "accuracy_without_tta = results[1]  # Assuming 'results' contains the accuracy without TTA\n",
    "print(f\"Accuracy without TTA: {accuracy_without_tta * 100:.2f}%\")\n",
    "print(f\"TTA Accuracy: {tta_accuracy * 100:.2f}%\")\n",
    "\n",
    "# 4. Distribution of Predicted Probabilities with TTA\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(np.max(tta_preds, axis=1), bins=20, alpha=0.7, label='TTA')\n",
    "plt.title('Distribution of Max Predicted Probabilities - TTA')\n",
    "plt.xlabel('Max Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 5. Learning Curves for Training with TTA\n",
    "# Assuming 'history' is from model training\n",
    "pd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot()\n",
    "plt.title(\"Training and Validation Accuracy with TTA\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grad Cam Visualization code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Feature extraction like i extracted in matlab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Paths\n",
    "dataset_dir = r\"E:\\Abroad period research\\new idea implementation codes\\First part of the Covid paper\\Original dataset\"\n",
    "model_path = 'Mobilenetv2.h5'\n",
    "\n",
    "# Load the pre-trained MobileNetV2 model\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Define the layer from which to extract features\n",
    "# For example, we can extract from the last convolutional layer 'Conv_1'\n",
    "feature_layer = model.get_layer('Conv_1')  # Modify the layer name as per your model's architecture\n",
    "\n",
    "# Create a model that outputs the activations from the feature extraction layer\n",
    "feature_extractor_model = Model(inputs=model.input, outputs=feature_layer.output)\n",
    "\n",
    "# Image preprocessing using ImageDataGenerator\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Load images from the dataset\n",
    "batch_size = 32  # Adjust based on available memory\n",
    "img_size = (224, 224)  # Size expected by MobileNetV2\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Assuming you have multiple classes\n",
    "    shuffle=False  # No shuffling so that order of labels and features matches\n",
    ")\n",
    "\n",
    "# Extract features from the dataset\n",
    "num_samples = train_generator.samples\n",
    "num_batches = np.ceil(num_samples / batch_size)\n",
    "\n",
    "# Initialize a placeholder for storing extracted features\n",
    "features = []\n",
    "\n",
    "# Loop through the batches of images and extract features\n",
    "for x_batch, y_batch in train_generator:  # Iterating over the generator\n",
    "    features_batch = feature_extractor_model.predict(x_batch)  # Extract features\n",
    "    features.append(features_batch)\n",
    "\n",
    "    # Break the loop when all batches are processed\n",
    "    if len(features) >= num_batches:\n",
    "        break\n",
    "\n",
    "# Stack the list of feature batches into a single array\n",
    "features = np.vstack(features)\n",
    "\n",
    "# Get the labels corresponding to the features\n",
    "labels = train_generator.classes  # These are the true labels for each image\n",
    "\n",
    "# Save the extracted features and labels\n",
    "np.save('MobileNetV2_features.npy', features)\n",
    "np.save('MobileNetV2_labels.npy', labels)\n",
    "\n",
    "print(\"Feature extraction completed. Features and labels saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification of features using saved extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "# Load features and labels with memory mapping to avoid loading the entire dataset into memory\n",
    "features = np.load('MobileNetV2_features.npy', mmap_mode='r')  # shape: (num_samples, height, width, channels)\n",
    "labels = np.load('MobileNetV2_labels.npy')\n",
    "\n",
    "# Reshape features to 2D (num_samples, num_features)\n",
    "num_samples = features.shape[0]\n",
    "num_features = features.shape[1] * features.shape[2] * features.shape[3]\n",
    "\n",
    "# Use memory mapping for reshaped features\n",
    "features_reshaped = np.memmap('MobileNetV2_reshaped_features.dat', dtype='float32', mode='w+', shape=(num_samples, num_features))\n",
    "\n",
    "# Reshape features into a 2D array and downcast to float32 to reduce memory usage\n",
    "features_reshaped[:] = features.reshape(num_samples, num_features).astype(np.float32)\n",
    "\n",
    "# Use IncrementalPCA to reduce memory consumption by processing in batches\n",
    "n_components = 500  # Adjust this based on your memory constraints\n",
    "ipca = IncrementalPCA(n_components=n_components, batch_size=1000)\n",
    "\n",
    "# Create a memory-mapped file for the reduced features to avoid using RAM\n",
    "features_reduced = np.memmap('MobileNetV2_features_reduced.dat', dtype='float32', mode='w+', shape=(num_samples, n_components))\n",
    "\n",
    "# Apply PCA in batches and save the reduced features incrementally\n",
    "for i in range(0, num_samples, 1000):  # Process in batches of 1000 samples\n",
    "    batch = features_reshaped[i:i + 1000]\n",
    "    features_reduced[i:i + 1000] = ipca.partial_fit_transform(batch)\n",
    "\n",
    "# Save the reduced features (optional, if you want to use them later)\n",
    "np.save('MobileNetV2_features_reduced.npy', features_reduced)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_reduced, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a list of classifiers to use\n",
    "classifiers = {\n",
    "    'SVM': SVC(kernel='linear', random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, classifier_name):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Confusion Matrix for {classifier_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "# Loop over classifiers, train, predict, and evaluate\n",
    "for classifier_name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    plot_confusion_matrix(cm, classifier_name)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Print the results\n",
    "    print(f'Classifier: {classifier_name}')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print('-' * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Decision tree using statistical features and rule extraction using decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Load and preprocess image\n",
    "def get_img_array(img_path, size=(224, 224)):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "# Function to create heatmap using Grad-CAM\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=model.inputs,\n",
    "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# Function to save Grad-CAM visualization\n",
    "def save_gradcam(img_path, heatmap, output_dir, alpha=0.4):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save original and XAI image\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    original_img_name = Path(img_path).stem\n",
    "    original_img_path = os.path.join(output_dir, f\"{original_img_name}.png\")\n",
    "    cam_img_path = os.path.join(output_dir, f\"{original_img_name}_XAI.png\")\n",
    "\n",
    "    tf.keras.preprocessing.image.save_img(original_img_path, img)\n",
    "    superimposed_img.save(cam_img_path)\n",
    "\n",
    "# Paths and model loading\n",
    "dataset_dir = r\"E:\\Abroad period research\\new idea implementation codes\\First part of the Covid paper\\Cropped augmented dataset performance\\Augmented-Dataset\"\n",
    "model_path = r\"E:\\Abroad period research\\new idea implementation codes\\First part of the Covid paper\\Final codes\\Mobilenetv2_on_Cropped_augmented_dataset.h5\"\n",
    "output_base_dir = r\"E:\\GradCAM_Results\"\n",
    "\n",
    "# Load the model and specify layer name\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "last_conv_layer_name = \"Conv_1\"\n",
    "img_size = (224, 224)\n",
    "\n",
    "# Preprocess Input\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "# Loop through each subfolder and apply Grad-CAM\n",
    "for class_folder in os.listdir(dataset_dir):\n",
    "    class_folder_path = os.path.join(dataset_dir, class_folder)\n",
    "    \n",
    "    if os.path.isdir(class_folder_path):\n",
    "        print(f\"Processing class: {class_folder}\")\n",
    "        \n",
    "        # Create output folders\n",
    "        output_class_dir = os.path.join(output_base_dir, class_folder)\n",
    "        os.makedirs(output_class_dir, exist_ok=True)\n",
    "\n",
    "        # Limit to 50 images\n",
    "        image_files = [f for f in os.listdir(class_folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        image_files = image_files[:50]  # Limit to 50 images\n",
    "\n",
    "        # Process each image\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(class_folder_path, img_file)\n",
    "            img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
    "            \n",
    "            # Generate Grad-CAM heatmap\n",
    "            heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "            \n",
    "            # Save original and Grad-CAM images\n",
    "            save_gradcam(img_path, heatmap, output_class_dir)\n",
    "\n",
    "print(\"Grad-CAM visualizations generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

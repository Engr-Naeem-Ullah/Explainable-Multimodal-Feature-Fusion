{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ddc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to feature folders (excluding HOG features)\n",
    "feature_folders = [\n",
    "    r\"E:\\Abroad period research\\Feature Fusion paper\\Ultrasound Breast Cancer\\Features\\Frequency\",\n",
    "    r\"E:\\Abroad period research\\Feature Fusion paper\\Ultrasound Breast Cancer\\Features\\Gabor\",\n",
    "    r\"E:\\Abroad period research\\Feature Fusion paper\\Ultrasound Breast Cancer\\Features\\HOG\",\n",
    "    r\"E:\\Abroad period research\\Feature Fusion paper\\Ultrasound Breast Cancer\\Features\\Statistical\",\n",
    "    r\"E:\\Abroad period research\\Feature Fusion paper\\Ultrasound Breast Cancer\\Features\\LBP_Features\"\n",
    "  ]\n",
    "\n",
    "# Output folder to save concatenated features\n",
    "output_folder = r\"E:\\Abroad period research\\Feature Fusion paper\\Ultrasound Breast Cancer\\Features\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Names of files to concatenate\n",
    "file_names = [\"train.csv\", \"val.csv\", \"test.csv\"]\n",
    "\n",
    "# Function to concatenate features from multiple folders for a specific file type (train, val, test)\n",
    "def concatenate_features(file_name, feature_folders, output_folder):\n",
    "    combined_df = None  # Initialize an empty DataFrame\n",
    "    \n",
    "    for folder_path in feature_folders:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            # Read the feature file\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Check if 'label' exists in the DataFrame\n",
    "            if 'label' in df.columns:\n",
    "                if combined_df is None:  # First folder, keep 'label'\n",
    "                    combined_df = df\n",
    "                else:  # Drop 'label' in subsequent folders to avoid duplicates\n",
    "                    combined_df = pd.concat([combined_df, df.drop('label', axis=1)], axis=1)\n",
    "            else:\n",
    "                if combined_df is None:  # If no label column, set the first combined_df\n",
    "                    combined_df = df\n",
    "                else:\n",
    "                    combined_df = pd.concat([combined_df, df], axis=1)\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "    \n",
    "    # Ensure the 'label' column is included as the last column\n",
    "    if 'label' in combined_df.columns:\n",
    "        label = combined_df['label']\n",
    "        combined_df = combined_df.drop(columns=['label'])\n",
    "        combined_df['label'] = label  # Move 'label' to the end\n",
    "\n",
    "    # Save the concatenated features to the output folder\n",
    "    output_path = os.path.join(output_folder, file_name)\n",
    "    combined_df.to_csv(output_path, index=False)\n",
    "    print(f\"Concatenated {file_name} saved to: {output_path}\")\n",
    "\n",
    "# Loop through train, val, and test files\n",
    "for file_name in file_names:\n",
    "    concatenate_features(file_name, feature_folders, output_folder)\n",
    "\n",
    "print(\"Feature concatenation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b678c8a3",
   "metadata": {},
   "source": [
    "Classification using decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e586812",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths to the combined feature files\n",
    "combined_features_path = r\"E:\\Abroad period research\\Feature Fusion paper\\Ultrasound Breast Cancer\\Features\"\n",
    "\n",
    "# Load train, val, and test datasets\n",
    "try:\n",
    "    train_df = pd.read_csv(os.path.join(combined_features_path, \"train.csv\"))\n",
    "    val_df = pd.read_csv(os.path.join(combined_features_path, \"val.csv\"))\n",
    "    test_df = pd.read_csv(os.path.join(combined_features_path, \"test.csv\"))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    raise\n",
    "\n",
    "# Combine the train and val datasets\n",
    "combined_train_val_df = pd.concat([train_df, val_df], ignore_index=True)\n",
    "\n",
    "# Ensure label column exists in both combined train-val and test datasets\n",
    "if 'label' not in combined_train_val_df.columns or 'label' not in test_df.columns:\n",
    "    raise ValueError(\"The 'label' column is missing in one of the datasets.\")\n",
    "\n",
    "# Split the features (X) and labels (y) for the training-validation set\n",
    "X_train_val = combined_train_val_df.drop(columns=['label'])  # Features\n",
    "y_train_val = combined_train_val_df['label']  # Labels\n",
    "\n",
    "# Split the features (X) and labels (y) for the test set\n",
    "X_test = test_df.drop(columns=['label'])  # Features\n",
    "y_test = test_df['label']  # Labels\n",
    "\n",
    "# Check for any missing values in the datasets\n",
    "if X_train_val.isnull().values.any() or X_test.isnull().values.any():\n",
    "    print(\"Warning: Missing values found in features. Please handle missing data before training.\")\n",
    "\n",
    "# ---- Grid Search for Hyperparameter Optimization ----\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, \n",
    "                           scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Optimized Hyperparameters:\")\n",
    "print(best_params)\n",
    "\n",
    "# Get the best estimator from Grid Search\n",
    "best_dt_classifier = grid_search.best_estimator_\n",
    "\n",
    "# ---- Training Evaluation ----\n",
    "# Make predictions on the training data\n",
    "y_train_pred = best_dt_classifier.predict(X_train_val)\n",
    "\n",
    "# Training confusion matrix\n",
    "train_cm = confusion_matrix(y_train_val, y_train_pred)\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(train_cm)\n",
    "\n",
    "# Plot training confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(train_cm, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=[f'Class {i}' for i in range(len(set(y_train_val)))],\n",
    "            yticklabels=[f'Class {i}' for i in range(len(set(y_train_val)))])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Training Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Training classification report\n",
    "print(\"\\nTraining Classification Report:\")\n",
    "print(classification_report(y_train_val, y_train_pred, digits=4))\n",
    "\n",
    "# Training accuracy\n",
    "train_accuracy = accuracy_score(y_train_val, y_train_pred)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "# ---- Testing Evaluation ----\n",
    "# Make predictions on the test data\n",
    "y_test_pred = best_dt_classifier.predict(X_test)\n",
    "\n",
    "# Testing confusion matrix\n",
    "test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Testing Confusion Matrix:\")\n",
    "print(test_cm)\n",
    "\n",
    "# Plot testing confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(test_cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[f'Class {i}' for i in range(len(set(y_test)))],\n",
    "            yticklabels=[f'Class {i}' for i in range(len(set(y_test)))])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Testing Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Testing classification report\n",
    "print(\"\\nTesting Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, digits=4))\n",
    "\n",
    "# Testing accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

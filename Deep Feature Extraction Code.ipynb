{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a86124",
   "metadata": {},
   "source": [
    "Deep Feature Extraction from trained DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b300265",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Function to print with Markdown\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "\n",
    "# Load and preprocess dataset\n",
    "image_dir = Path(r'E:\\Abroad period research\\new idea implementation codes\\Second part of the paper\\Ultrasound Breast Images for Breast Cancer\\26 features results\\dataset')\n",
    "\n",
    "filepaths = list(image_dir.glob(r'**/*.png'))\n",
    "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "image_df = pd.concat([filepaths, labels], axis=1)\n",
    "image_df = image_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "train_df, temp_df = train_test_split(image_df, train_size=0.7, shuffle=True, random_state=1)\n",
    "val_df, test_df = train_test_split(temp_df, train_size=0.5, shuffle=True, random_state=1)\n",
    "\n",
    "# Create data generators with augmentation\n",
    "def create_gen():\n",
    "    train_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    val_test_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "    )\n",
    "\n",
    "    train_images = train_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        seed=0\n",
    "    )\n",
    "\n",
    "    val_images = val_test_generator.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    test_images = val_test_generator.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_images, val_images, test_images\n",
    "\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_path = r'E:\\Abroad period research\\new idea implementation codes\\Second part of the paper\\Ultrasound Breast Images for Breast Cancer\\26 features results\\Mobilenetv2_finetuned_on_breastcancer_dataset.h5'\n",
    "loaded_model = load_model(model_path)\n",
    "\n",
    "# Define the feature extraction model\n",
    "# Adjust the layer as needed; here, we use the fourth-last layer's output\n",
    "feature_extractor = Model(inputs=loaded_model.input, outputs=loaded_model.layers[-4].output)\n",
    "\n",
    "# Directory to save extracted features\n",
    "feature_dir = r'E:\\Abroad period research\\new idea implementation codes\\Second part of the paper\\Ultrasound Breast Images for Breast Cancer\\26 features results\\extracted_features'\n",
    "os.makedirs(feature_dir, exist_ok=True)\n",
    "\n",
    "def extract_features(data_gen, set_name):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # Loop through batches in the data generator\n",
    "    for batch_images, batch_labels in data_gen:\n",
    "        # Extract features for the batch\n",
    "        batch_features = feature_extractor.predict(batch_images)\n",
    "        features.extend(batch_features)\n",
    "        labels.extend(batch_labels)\n",
    "        \n",
    "        # Break if weâ€™ve covered all images in the generator\n",
    "        if data_gen.batch_index == 0:\n",
    "            break\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Save extracted features and labels to a file\n",
    "    with open(os.path.join(feature_dir, f\"{set_name}_features.pkl\"), 'wb') as f:\n",
    "        pickle.dump((features, labels), f)\n",
    "\n",
    "# Create data generators with augmentation\n",
    "train_images, val_images, test_images = create_gen()\n",
    "\n",
    "# Extract features for training, validation, and test sets\n",
    "extract_features(train_images, \"train\")\n",
    "extract_features(val_images, \"val\")\n",
    "extract_features(test_images, \"test\")\n",
    "\n",
    "print(\"Features extracted and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb97b11",
   "metadata": {},
   "source": [
    "Classification of features using saved extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc87ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Directory to save extracted features and models\n",
    "feature_dir = r'E:\\Abroad period research\\new idea implementation codes\\Second part of the paper\\Ultrasound Breast Images for Breast Cancer\\26 features results\\extracted_features'\n",
    "model_dir = r'E:\\Abroad period research\\new idea implementation codes\\Second part of the paper\\Ultrasound Breast Images for Breast Cancer\\26 features results\\saved_models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Load extracted features\n",
    "with open(os.path.join(feature_dir, \"train_features.pkl\"), 'rb') as f:\n",
    "    train_features, train_labels = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(feature_dir, \"val_features.pkl\"), 'rb') as f:\n",
    "    val_features, val_labels = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(feature_dir, \"test_features.pkl\"), 'rb') as f:\n",
    "    test_features, test_labels = pickle.load(f)\n",
    "\n",
    "# Convert one-hot encoded labels to single-class labels\n",
    "train_labels = np.argmax(train_labels, axis=1)\n",
    "val_labels = np.argmax(val_labels, axis=1)\n",
    "test_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "# Train Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "# Save the trained Decision Tree model\n",
    "tree_model_path = os.path.join(model_dir, 'decision_tree_model.pkl')\n",
    "with open(tree_model_path, 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "# Evaluate on training, validation, and test sets\n",
    "for set_name, features, labels in [(\"Train\", train_features, train_labels), (\"Validation\", val_features, val_labels), (\"Test\", test_features, test_labels)]:\n",
    "    predictions = clf.predict(features)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    print(f\"{set_name} Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"{set_name} Confusion Matrix:\\n\", confusion_matrix(labels, predictions))\n",
    "    print(f\"{set_name} Classification Report:\\n\", classification_report(labels, predictions))\n",
    "\n",
    "print(f\"Decision Tree model saved to: {tree_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4c5d80",
   "metadata": {},
   "source": [
    "Classification using Rulefit on the extracted deep features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3895cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from rulefit import RuleFit\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Directory to save extracted features and models\n",
    "feature_dir = r'E:\\Abroad period research\\new idea implementation codes\\Second part of the paper\\Ultrasound Breast Images for Breast Cancer\\26 features results\\extracted_features'\n",
    "model_dir = r'E:\\Abroad period research\\new idea implementation codes\\Second part of the paper\\Ultrasound Breast Images for Breast Cancer\\26 features results\\saved_models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Load extracted features\n",
    "with open(os.path.join(feature_dir, \"train_features.pkl\"), 'rb') as f:\n",
    "    train_features, train_labels = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(feature_dir, \"val_features.pkl\"), 'rb') as f:\n",
    "    val_features, val_labels = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(feature_dir, \"test_features.pkl\"), 'rb') as f:\n",
    "    test_features, test_labels = pickle.load(f)\n",
    "\n",
    "# Check shapes of features and labels\n",
    "print(\"Train Features Shape:\", train_features.shape)\n",
    "print(\"Train Labels Shape:\", train_labels.shape)\n",
    "print(\"Validation Features Shape:\", val_features.shape)\n",
    "print(\"Validation Labels Shape:\", val_labels.shape)\n",
    "\n",
    "# Ensure labels are aligned with features\n",
    "assert train_features.shape[0] == train_labels.shape[0], \"Mismatch between train features and labels.\"\n",
    "assert val_features.shape[0] == val_labels.shape[0], \"Mismatch between validation features and labels.\"\n",
    "\n",
    "# Convert multi-dimensional labels to single class labels (if needed)\n",
    "train_labels = np.argmax(train_labels, axis=1)  # Assuming one-hot encoding\n",
    "val_labels = np.argmax(val_labels, axis=1)      # Assuming one-hot encoding\n",
    "test_labels = np.argmax(test_labels, axis=1)    # If test labels are also one-hot encoded\n",
    "\n",
    "# Combine training and validation data for final training\n",
    "train_val_features = np.vstack([train_features, val_features])\n",
    "train_val_labels = np.hstack([train_labels, val_labels])\n",
    "\n",
    "print(f\"Combined Training + Validation Features Shape: {train_val_features.shape}\")\n",
    "print(f\"Combined Training + Validation Labels Shape: {train_val_labels.shape}\")\n",
    "\n",
    "# Initialize RuleFit model\n",
    "rf = RuleFit(tree_size=3, sample_fract=1.0, max_rules=2000, random_state=42)\n",
    "\n",
    "# Fit the RuleFit model to combined training and validation data\n",
    "rf.fit(train_val_features, train_val_labels)\n",
    "\n",
    "# Predict on the test set (continuous values)\n",
    "test_predictions = rf.predict(test_features)\n",
    "\n",
    "# Convert continuous predictions to discrete class labels by rounding or using a threshold\n",
    "test_predictions_discrete = np.round(test_predictions).astype(int)\n",
    "\n",
    "# Ensure the predicted labels are within the valid range of classes\n",
    "test_predictions_discrete = np.clip(test_predictions_discrete, np.min(train_val_labels), np.max(train_val_labels))\n",
    "\n",
    "# Calculate testing accuracy\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions_discrete)\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions_discrete)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"{set_name} Confusion Matrix:\\n\", confusion_matrix(test_labels, test_predictions_discrete))\n",
    "print(f\"{set_name} Classification Report:\\n\", classification_report(test_labels, test_predictions_discrete))\n",
    "\n",
    "# Extract rules from the RuleFit model\n",
    "rules = rf.get_rules()\n",
    "rules = rules[rules.coef != 0].sort_values(\"importance\", ascending=False)\n",
    "\n",
    "# Display the top rules\n",
    "print(\"Top Rules from RuleFit Model:\")\n",
    "print(rules.head())\n",
    "\n",
    "# Save rules to a text file\n",
    "output_file_path = r'E:\\Abroad period research\\new idea implementation codes\\Second part of the paper\\Ultrasound Breast Images for Breast Cancer\\26 features results\\rulefit_rules_on_deep_features.txt'\n",
    "rules.to_csv(output_file_path, index=False)\n",
    "print(f\"Rules have been saved to {output_file_path}.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

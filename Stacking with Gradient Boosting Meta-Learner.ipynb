{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78fa5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. Load feature files\n",
    "def load_feature_files(base_path):\n",
    "    \"\"\"Load train, validation, and test CSV files from each feature folder.\"\"\"\n",
    "    feature_sets = [\"Frequency\", \"Gabor\", \"HOG\", \"Statistical\", \"ColorHistogram\"]\n",
    "    data = {}\n",
    "\n",
    "    for feature in feature_sets:\n",
    "        train_path = os.path.join(base_path, feature, \"train.csv\")\n",
    "        val_path = os.path.join(base_path, feature, \"val.csv\")\n",
    "        test_path = os.path.join(base_path, feature, \"test.csv\")\n",
    "\n",
    "        data[feature] = {\n",
    "            \"train\": pd.read_csv(train_path),\n",
    "            \"val\": pd.read_csv(val_path),\n",
    "            \"test\": pd.read_csv(test_path),\n",
    "        }\n",
    "\n",
    "    return data\n",
    "\n",
    "# Update the path to your dataset\n",
    "base_path = r\"E:\\Abroad period research\\Feature Fusion paper\\Eye dataset\\Final codes for github\\Features\"\n",
    "data = load_feature_files(base_path)\n",
    "\n",
    "# 2. Combine train and val files, then split features and labels\n",
    "def combine_and_split_features(data):\n",
    "    \"\"\"Combine train and val datasets, and split features and labels.\"\"\"\n",
    "    X_train_val, y_train_val = {}, {}\n",
    "    X_test, y_test = {}, {}\n",
    "\n",
    "    for feature, datasets in data.items():\n",
    "        # Combine train and val datasets\n",
    "        combined_train_val = pd.concat([datasets[\"train\"], datasets[\"val\"]], ignore_index=True)\n",
    "\n",
    "        # Split features and labels\n",
    "        X_train_val[feature] = combined_train_val.iloc[:, :-1]  # All columns except last\n",
    "        y_train_val[feature] = combined_train_val.iloc[:, -1]  # Last column as label\n",
    "        X_test[feature] = datasets[\"test\"].iloc[:, :-1]\n",
    "        y_test[feature] = datasets[\"test\"].iloc[:, -1]\n",
    "\n",
    "    return X_train_val, y_train_val, X_test, y_test\n",
    "\n",
    "X_train_val, y_train_val, X_test, y_test = combine_and_split_features(data)\n",
    "\n",
    "# 3. Train individual classifiers\n",
    "def train_classifiers(X_train, y_train):\n",
    "    \"\"\"Train individual classifiers for each feature set.\"\"\"\n",
    "    classifiers = {}\n",
    "\n",
    "    for feature, X in X_train.items():\n",
    "        print(f\"Training Decision Tree on {feature} features...\")\n",
    "        clf = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "        clf.fit(X, y_train[feature])\n",
    "        classifiers[feature] = clf\n",
    "\n",
    "    return classifiers\n",
    "\n",
    "classifiers = train_classifiers(X_train_val, y_train_val)\n",
    "\n",
    "# 4. Prepare combined feature sets\n",
    "def combine_features(X_train, X_test):\n",
    "    \"\"\"Combine feature sets for stacking.\"\"\"\n",
    "    X_train_combined = pd.concat([X_train[feature] for feature in X_train.keys()], axis=1)\n",
    "    X_test_combined = pd.concat([X_test[feature] for feature in X_test.keys()], axis=1)\n",
    "    return X_train_combined, X_test_combined\n",
    "\n",
    "X_train_combined, X_test_combined = combine_features(X_train_val, X_test)\n",
    "\n",
    "# Use labels from one feature set (they are the same for all sets)\n",
    "y_train_combined = y_train_val[next(iter(classifiers.keys()))]\n",
    "y_test_combined = y_test[next(iter(classifiers.keys()))]\n",
    "\n",
    "# 5. Stacking Classifier\n",
    "def create_stacking_classifier(X_train_combined, y_train_combined, X_test_combined, y_test_combined):\n",
    "    \"\"\"\n",
    "    Create and train a StackingClassifier for improved accuracy.\n",
    "    \"\"\"\n",
    "    # Base classifiers\n",
    "    base_estimators = [\n",
    "        (\"dt_frequency\", classifiers[\"Frequency\"]),\n",
    "        (\"dt_gabor\", classifiers[\"Gabor\"]),\n",
    "        # (\"dt_lbp\", classifiers[\"LBP\"]),\n",
    "        (\"dt_hog\", classifiers[\"HOG\"]),\n",
    "        (\"dt_statistical\", classifiers[\"Statistical\"]),\n",
    "    ]\n",
    "\n",
    "# [\"Frequency\", \"Gabor\", \"HOG\", \"Statistical\"]\n",
    "\n",
    "    # Meta-classifier\n",
    "    meta_clf = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "    # Stacking Classifier\n",
    "    stacking_clf = StackingClassifier(estimators=base_estimators, final_estimator=meta_clf, cv=5)\n",
    "    \n",
    "    print(\"\\nTraining Stacking Classifier...\")\n",
    "    stacking_clf.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    print(\"\\nEvaluating Stacking Classifier...\")\n",
    "    y_pred = stacking_clf.predict(X_test_combined)\n",
    "    print(classification_report(y_test_combined, y_pred, digits=4))\n",
    "\n",
    "    return stacking_clf, y_pred\n",
    "\n",
    "# Call the function\n",
    "stacking_clf, stacking_predictions = create_stacking_classifier(\n",
    "    X_train_combined, y_train_combined, X_test_combined, y_test_combined\n",
    ")\n",
    "\n",
    "# 6. Print Stacking Classifier Accuracy\n",
    "stacking_accuracy = accuracy_score(y_test_combined, stacking_predictions)\n",
    "print(f\"Stacking Classifier Accuracy: {stacking_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768a12a4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
